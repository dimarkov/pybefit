{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%matplotlib inline\n",
    "\n",
    "backend = \"torch\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A brief tutorial for how to use agent.Discrete class from pybefit to define a computational model of behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from jax import nn, random\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if backend == \"torch\":\n",
    "    tensor = torch\n",
    "    LONG = torch.long\n",
    "    one_hot = torch.nn.functional.one_hot\n",
    "    sigmoid = torch.sigmoid\n",
    "\n",
    "    class Cat(object):\n",
    "        def __init__(self, seed=0):\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        def __call__(self, logits):\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            return dist.sample()\n",
    "\n",
    "else:\n",
    "    tensor = jnp\n",
    "    LONG = jnp.int32\n",
    "    one_hot = nn.one_hot\n",
    "    sigmoid = nn.sigmoid\n",
    "\n",
    "    class Cat(object):\n",
    "        def __init__(self, seed=0):\n",
    "            self.key = random.PRNGKey(seed)\n",
    "\n",
    "        def __call__(self, logits):\n",
    "            self.key, key = random.split(self.key)\n",
    "            return random.categorical(key, logits)\n",
    "\n",
    "\n",
    "categorical = Cat(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# One would access this class using 'from pybefit.agents import Discrete'.\n",
    "# Note that each of the methods has to be implemented for simulations and inference to be possible with using pybefit classes\n",
    "\n",
    "\n",
    "class Discrete(object):\n",
    "    \"\"\"Agent with discrete and finite number of actions.\"\"\"\n",
    "\n",
    "    def __init__(self, runs, blocks, trials, na, ns, no):\n",
    "        self.runs = (\n",
    "            runs  # number of independent runs of the experiment or agents/subjects\n",
    "        )\n",
    "        self.nb = blocks  # number of experimental blocks\n",
    "        self.nt = trials  # number of trials in each block\n",
    "\n",
    "        self.na = na  # number of actions\n",
    "        self.ns = ns  # number of states\n",
    "        self.no = no  # number of outcomes\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Return the number of model parameters\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_parameters(self, *args, **kwargs):\n",
    "        \"\"\"Set free model parameters.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_beliefs(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Update beliefs about hidden states given some sensory stimuli and action outcomes.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def planning(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Compute choice probabilities in current block and trial.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample_responses(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate responses given response probability.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a simple agent solving a static multi armed bandit task based on the UCB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MABUCB(Discrete):\n",
    "    def __init__(self, runs=1, blocks=1, trials=1, num_arms=2):\n",
    "        # define bernoulli bandit with two outcomes (0, 1) for each arm\n",
    "        super().__init__(runs, blocks, trials, num_arms, num_arms, 2)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 3\n",
    "\n",
    "    def set_parameters(self, z):\n",
    "        self.lr = sigmoid(z[..., 0])  # learning rate\n",
    "        self.c = tensor.exp(z[..., 1])  # exploration strength\n",
    "        self.beta = tensor.exp(z[..., 2])  # response noise\n",
    "\n",
    "        self.q = tensor.zeros((self.runs, self.na))  # q values\n",
    "        self.count = tensor.zeros((self.runs, self.na))  # response count\n",
    "\n",
    "    def update_beliefs(self, block, trial, response_outcome):\n",
    "        # encode reponses as zero/one array where one is assigned to the chosen arm and zero to all other arms\n",
    "        response = one_hot(response_outcome[0], self.na)\n",
    "\n",
    "        # add one dimension to the right to outcomes to match dimensionality of responses\n",
    "        obs = tensor.broadcast_to(response_outcome[1][..., None], self.q.shape)\n",
    "\n",
    "        alpha = self.lr[..., None] / (self.count + 1)\n",
    "\n",
    "        # implements self.q[..., response] += alpha * (outcome - self.q[..., response])\n",
    "        self.q += alpha * response * (obs - self.q)\n",
    "        self.count += response\n",
    "\n",
    "    def planning(self, block, trial, *args, **kwargs):\n",
    "        logits = self.q + self.c[..., None] * tensor.sqrt(\n",
    "            tensor.log(trial + tensor.ones(1)) / (self.count + 1e-6)\n",
    "        )\n",
    "        return self.beta[..., None] * logits\n",
    "\n",
    "    def sample_responses(self, block, trial, logits, *args, **kwargs):\n",
    "        return categorical(logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define a task environmnet for the multi armed bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (10, 20, 100, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.],      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As with the agent implementation we start with a base Task class which is imported as \"from pybefit.task import Task\"\n",
    "class Task(object):\n",
    "    def __init__(self, nsub, blocks, trials):\n",
    "        self.blocks = blocks  # number of experimental blocks\n",
    "        self.trials = trials  # number of trials\n",
    "        self.nsub = nsub  # number of subjects\n",
    "\n",
    "    def get_offer(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Define an offer for a current block, trial pair that defines a unique stimuli\"\"\"\n",
    "\n",
    "        return None\n",
    "\n",
    "    def update_environment(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate stimuli for task's current block and trial\"\"\"\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MABTask(Task):\n",
    "    def __init__(self, outcomes):\n",
    "        blocks, trials, nsub, _ = outcomes.shape\n",
    "        super().__init__(nsub, blocks, trials)\n",
    "        self.outcomes = outcomes\n",
    "\n",
    "    def update_environment(self, block, trial, responses):\n",
    "        return self.outcomes[block, trial, list(range(self.nsub)), responses]\n",
    "\n",
    "\n",
    "blocks = 10\n",
    "trials = 20\n",
    "num_arms = 3\n",
    "num_subjects = 100\n",
    "\n",
    "probs = np.random.dirichlet(np.ones(num_arms), size=(blocks, 1, num_subjects))\n",
    "outcomes = tensor.ones(1) * np.random.binomial(\n",
    "    1, probs, size=(blocks, trials, num_subjects, num_arms)\n",
    ").astype(np.float32)\n",
    "\n",
    "print(outcomes.dtype, outcomes.shape)\n",
    "\n",
    "mab_task = MABTask(outcomes)\n",
    "mab_task.update_environment(0, 0, tensor.zeros(num_subjects, dtype=LONG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_agent = MABUCB(runs=num_subjects, blocks=blocks, trials=trials, num_arms=num_arms)\n",
    "\n",
    "z = tensor.ones(1) * np.random.standard_normal(\n",
    "    size=(num_subjects, mab_agent.num_params)\n",
    ").astype(np.float32)\n",
    "\n",
    "mab_agent.set_parameters(z)\n",
    "\n",
    "# run for a single time step\n",
    "logits = mab_agent.planning(0, 0)\n",
    "actions = mab_agent.sample_responses(0, 0, logits)\n",
    "obs = mab_task.update_environment(0, 0, actions)\n",
    "mab_agent.update_beliefs(0, 0, [actions, obs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
