{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%matplotlib inline\n",
    "\n",
    "backend = \"torch\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A brief tutorial for how to use agent.Discrete class from pybefit to define a computational model of behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from jax import nn, random\n",
    "\n",
    "if backend == \"torch\":\n",
    "    tensor = torch\n",
    "    one_hot = torch.nn.functional.one_hot\n",
    "    sigmoid = torch.nn.functional.sigmoid\n",
    "\n",
    "    class Cat(object):\n",
    "        def __init__(self, seed=0):\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        def __call__(self, logits):\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            return dist.sample()\n",
    "\n",
    "else:\n",
    "    tensor = jnp\n",
    "    one_hot = nn.one_hot\n",
    "    sigmoid = nn.sigmoid\n",
    "\n",
    "    class Cat(object):\n",
    "        def __init__(self, seed=0):\n",
    "            self.key = random.PRNGKey(seed)\n",
    "\n",
    "        def __call__(self, logits):\n",
    "            self.key, key = random.split(self.key)\n",
    "            return random.categorical(key, logits)\n",
    "\n",
    "\n",
    "categorical = Cat(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# One would access this class using 'from pybefit.agents import Discrete'.\n",
    "# Note that each of the methods has to be implemented for simulations and inference to be possible with using pybefit classes\n",
    "\n",
    "class Discrete(object):\n",
    "    \"\"\"Agent with discrete and finite number of actions.\n",
    "    \"\"\"\n",
    "    def __init__(self, runs, blocks, trials, na, ns, no):\n",
    "        \n",
    "        self.runs = runs  # number of independent runs of the experiment or agents/subjects\n",
    "        self.nb = blocks  # number of experimental blocks\n",
    "        self.nt = trials  # number of trials in each block\n",
    "        \n",
    "        self.na = na  # number of actions\n",
    "        self.ns = ns  # number of states\n",
    "        self.no = no  # number of outcomes\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Return the number of model parameters\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def set_parameters(self, *args, **kwargs):\n",
    "        \"\"\"Set free model parameters.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def update_beliefs(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Update beliefs about hidden states given some sensory stimuli and action outcomes.\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def planning(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Compute choice probabilities in current block and trial.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def sample_responses(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate responses given response probability.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a simple agent solving a static multi armed bandit task based on the UCB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MABAgent(Discrete):\n",
    "\n",
    "    def __init__(self, runs=1, blocks=1, trials=1, num_arms=2):\n",
    "        # define bernoulli bandit with two outcomes (0, 1) for each arm\n",
    "        super().__init__(runs, blocks, trials, num_arms, num_arms, 2)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 2\n",
    "    \n",
    "    def set_parameters(self, z):\n",
    "        self.lr = sigmoid( z[..., -1] )  # learning rate\n",
    "        self.beta = tensor.exp( z[..., -1] )  # exploration strength\n",
    "\n",
    "        self.q = tensor.zeros()  # q values\n",
    "        self.count = tensor.zeros()  # response count\n",
    "\n",
    "    def update_beliefs(self, block, trial, response_outcome):\n",
    "        \n",
    "        # encode reponses as zero/one array where one is assigned to the chosen arm and zero to all other arms\n",
    "        response = one_hot(response_outcome[0], self.na)\n",
    "\n",
    "        # add one dimension to the right to outcomes to match dimensionality of responses\n",
    "        outcome = response_outcome[1][..., None] \n",
    "\n",
    "\n",
    "        alpha = self.lr / (self.count + 1)\n",
    "\n",
    "        # implements self.q[..., response] += alpha * (outcome - self.q[..., response])\n",
    "        self.q += alpha * response * (outcome[..., None] - self.q)\n",
    "        self.count += response\n",
    "\n",
    "    def planning(self, block, trial, *args, **kwargs):\n",
    "        \n",
    "        self.logits = self.q + self.beta * tensor.sqrt( tensor.log(trial + 1)/(self.count + 1e-6) )\n",
    "        return self.logits \n",
    "        \n",
    "    def sample_responses(self, block, trial, *args, **kwargs):\n",
    "\n",
    "        return categorical(self.logits)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define a task environmnet for the multi armed bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As with the agent implementation we start with a base Task class which is imported as \"from pybefit.task import Task\"\n",
    "\n",
    "class Task(object):\n",
    "    def __init__(self, nsub, blocks, trials):\n",
    "        self.blocks = blocks  # number of experimental blocks\n",
    "        self.trials = trials  # number of trials\n",
    "        self.nsub = nsub  # number of subjects\n",
    "\n",
    "    def get_offer(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Define an offer for a current block, trial pair that defines a unique stimuli\"\"\"\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def update_environment(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate stimuli for task's current block and trial\"\"\"\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MABTask(Task):\n",
    "    def __init__(self, outcomes):\n",
    "        blocks, trials, nsub, _ = outcomes.shape\n",
    "        super().__init__(nsub, blocks, trials)\n",
    "        self.outcomes = outcomes\n",
    "\n",
    "    def update_environment(self, block, trial, responses):\n",
    "        return self.outcomes[block, trial, range(self.nsub), responses]\n",
    "\n",
    "\n",
    "blocks = 10\n",
    "trials = 20\n",
    "num_arms = 3\n",
    "num_subjects = 100\n",
    "\n",
    "probs = np.random.dirichlet(np.ones(num_arms), size=(blocks, trials, num_subjects))\n",
    "\n",
    "outcomes = tensor.ones(1) * np.random.binomial(1, probs)\n",
    "print(outcomes.dtype)\n",
    "\n",
    "mab_task = MABTask(outcomes)\n",
    "mab_task.update_environment(0, 0, tensor.zeros(num_subjects, dtype=tensor.long))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
