{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%matplotlib inline\n",
    "\n",
    "backend = \"torch\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A brief tutorial for how to use agent.Discrete class from pybefit to define a computational model of behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from jax import nn, random\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if backend == \"torch\":\n",
    "    tensor = torch\n",
    "    LONG = torch.long\n",
    "    one_hot = torch.nn.functional.one_hot\n",
    "    sigmoid = torch.sigmoid\n",
    "    torch.manual_seed(seed=0)\n",
    "\n",
    "    class Cat(object):\n",
    "        def __call__(self, logits, *args):\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            return dist.sample()\n",
    "\n",
    "else:\n",
    "    tensor = jnp\n",
    "    LONG = jnp.int32\n",
    "    one_hot = nn.one_hot\n",
    "    sigmoid = nn.sigmoid\n",
    "\n",
    "    class Cat(object):\n",
    "        def __call__(self, logits, key):\n",
    "            return random.categorical(key, logits)\n",
    "\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "categorical = Cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# One would access this class using 'from pybefit.agents import Discrete'.\n",
    "# Note that each of the methods has to be implemented for simulations and inference to be possible with using pybefit classes\n",
    "\n",
    "\n",
    "class Discrete(object):\n",
    "    \"\"\"Agent with discrete and finite number of actions.\"\"\"\n",
    "\n",
    "    def __init__(self, runs, blocks, trials, na, ns, no):\n",
    "        self.runs = (\n",
    "            runs  # number of independent runs of the experiment or agents/subjects\n",
    "        )\n",
    "        self.nb = blocks  # number of experimental blocks\n",
    "        self.nt = trials  # number of trials in each block\n",
    "\n",
    "        self.na = na  # number of actions\n",
    "        self.ns = ns  # number of states\n",
    "        self.no = no  # number of outcomes\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Return the number of model parameters\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def get_beliefs(self):\n",
    "        \"\"\"Return a tuple of beliefs, that is, internal dynamical model states. Only used for\n",
    "        numpyro/jax based models\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_parameters(self, *args, **kwargs):\n",
    "        \"\"\"Set free model parameters.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_beliefs(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Update beliefs about hidden states given some sensory stimuli and action outcomes.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def planning(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Compute choice probabilities in current block and trial.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample_responses(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate responses given response probability.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a simple agent solving a static multi armed bandit task based on the UCB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class UCBAgent(Discrete):\n",
    "    def __init__(self, runs=1, blocks=1, trials=1, num_arms=2):\n",
    "        # define bernoulli bandit with two outcomes (0, 1) for each arm\n",
    "        super().__init__(runs, blocks, trials, num_arms, num_arms, 2)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 3\n",
    "\n",
    "    @property\n",
    "    def get_beliefs(self):\n",
    "        return (self.q, self.count)\n",
    "\n",
    "    def set_parameters(self, z):\n",
    "        self.lr = sigmoid(z[..., 0])  # learning rate\n",
    "        self.c = tensor.exp(z[..., 1])  # exploration strength\n",
    "        self.beta = tensor.exp(z[..., 2])  # response noise\n",
    "\n",
    "        self.q = tensor.zeros((self.runs, self.na))  # q values\n",
    "        self.count = tensor.zeros((self.runs, self.na))  # response count\n",
    "\n",
    "    def update_beliefs(self, block, trial, response_outcome, **kwargs):\n",
    "        # encode reponses as zero/one array where one is assigned to the chosen arm and zero to all other arms\n",
    "\n",
    "        q, count = kwargs.pop(\"beliefs\", self.get_beliefs)\n",
    "\n",
    "        response = one_hot(response_outcome[0], self.na)\n",
    "\n",
    "        # add one dimension to the right to outcomes to match dimensionality of responses\n",
    "        obs = response_outcome[1][..., None]\n",
    "\n",
    "        alpha = self.lr[..., None] / (count + 1)\n",
    "\n",
    "        # implements self.q[..., response] += alpha * (outcome - self.q[..., response])\n",
    "        self.q = q + alpha * response * (obs - q)\n",
    "        self.count = count + response\n",
    "\n",
    "        return self.get_beliefs\n",
    "\n",
    "    def planning(self, block, trial, **kwargs):\n",
    "        q, count = kwargs.pop(\"beliefs\", self.get_beliefs)\n",
    "\n",
    "        t = block * self.nt + trial\n",
    "        logits = q + self.c[..., None] * tensor.sqrt(\n",
    "            tensor.log(t + tensor.ones(1)) / (count + 1e-2)\n",
    "        )\n",
    "        return self.beta[..., None] * logits\n",
    "\n",
    "    def sample_responses(self, block, trial, logits, **kwargs):\n",
    "        key = kwargs.pop(\"key\", None)\n",
    "        return categorical(logits, key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define a task environmnet for the multi armed bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([10, 20, 100, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As with the agent implementation we start with a base Task class which is imported as \"from pybefit.task import Task\"\n",
    "class Task(object):\n",
    "    def __init__(self, nsub, blocks, trials):\n",
    "        self.blocks = blocks  # number of experimental blocks\n",
    "        self.trials = trials  # number of trials\n",
    "        self.nsub = nsub  # number of subjects\n",
    "\n",
    "    def get_offer(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Define an offer for a current block, trial pair that defines a unique stimuli\"\"\"\n",
    "\n",
    "        return None\n",
    "\n",
    "    def update_environment(self, block, trial, *args, **kwargs):\n",
    "        \"\"\"Generate stimuli for task's current block and trial\"\"\"\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MABTask(Task):\n",
    "    def __init__(self, outcomes):\n",
    "        blocks, trials, nsub, num_arms = outcomes.shape\n",
    "        super().__init__(nsub, blocks, trials)\n",
    "        self.outcomes = outcomes\n",
    "        self.num_arms = num_arms\n",
    "\n",
    "    def update_environment(self, block, trial, responses):\n",
    "        return tensor.sum(\n",
    "            self.outcomes[block, trial] * one_hot(responses, self.num_arms), -1\n",
    "        )\n",
    "\n",
    "\n",
    "blocks = 10\n",
    "trials = 20\n",
    "num_arms = 3\n",
    "num_subjects = 100\n",
    "\n",
    "probs = np.random.dirichlet(np.ones(num_arms), size=(num_subjects))\n",
    "outcomes = tensor.ones(1) * np.random.binomial(\n",
    "    1, probs, size=(blocks, trials, num_subjects, num_arms)\n",
    ").astype(np.float32)\n",
    "\n",
    "print(outcomes.dtype, outcomes.shape)\n",
    "\n",
    "mab_task = MABTask(outcomes)\n",
    "mab_task.update_environment(0, 0, tensor.zeros(num_subjects, dtype=LONG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_agent = UCBAgent(runs=num_subjects, blocks=blocks, trials=trials, num_arms=num_arms)\n",
    "\n",
    "z = tensor.ones(1) * np.random.standard_normal(\n",
    "    size=(num_subjects, mab_agent.num_params)\n",
    ").astype(np.float32)\n",
    "\n",
    "mab_agent.set_parameters(z)\n",
    "\n",
    "# run for a single time step\n",
    "logits = mab_agent.planning(0, 0)\n",
    "actions = mab_agent.sample_responses(0, 0, logits, key=rng_key)\n",
    "obs = mab_task.update_environment(0, 0, actions)\n",
    "beliefs = mab_agent.get_beliefs\n",
    "new_beliefs = mab_agent.update_beliefs(0, 0, [actions, obs], beliefs=beliefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
